{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Score Relevance\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook is part of a series dedicated to building a relevance score model. The goal is to differentiate relevant news articles from two distinct sources:\n",
    "- Target 1: News from [Yahoo Finance on Crypto](https://finance.yahoo.com/topic/crypto) \n",
    "- Target 0: General news from [Yahoo News](https://news.yahoo.com)\n",
    "\n",
    "The model employs a pipeline combining `TfidfVectorizer` and `MultinomialNB` (Naive Bayes) for classification.\n",
    "\n",
    "## Notebook Objective\n",
    "\n",
    "`Relevance_Analysis_GA.ipynb` focuses on training a supervised relevance score model using the `all_score_training.csv` dataset. This model is then applied to classify news articles downloaded from Gdelt in an additive manner.\n",
    "\n",
    "- **Development Dataset**: `all_score_training.csv`\n",
    "- **Deployment Dataset**: \n",
    "    - **Input**: `GA_data.csv`\n",
    "    - **Output**: `GA_data_wrelevance.csv`\n",
    "\n",
    "## Model Training Approach\n",
    "\n",
    "The training involves several key steps:\n",
    "1. **Data Preprocessing**: Utilizing custom transformers for text cleaning, stop words removal, and lemmatization.\n",
    "2. **Feature Extraction**: Applying `TfidfVectorizer` to convert text data into a format suitable for model training.\n",
    "3. **Model Training**: Employing `MultinomialNB` within a pipeline for classification.\n",
    "4. **Evaluation**: Assessing the model's performance using metrics such as accuracy, precision, recall, F1 score, and ROC AUC.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "The process begins with essential imports and data loading. Custom transformers (`TextCleaner`, `StopWordsRemover`, `Lemmatizer`) are defined for data preprocessing, followed by the establishment of a pipeline integrating these transformers with `TfidfVectorizer` and `MultinomialNB`.\n",
    "\n",
    "The dataset `all_score_training.csv` is used for training, with the target variable indicating the relevance of news articles (1 for relevant, 0 for non-relevant). The pipeline is trained and evaluated on this dataset, and performance metrics are reported.\n",
    "\n",
    "Finally, the trained model is saved for future use in classifying new datasets, demonstrated by applying it to `GA_data.csv` and producing `GA_data_wrelevance.csv`.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook showcases the end-to-end process of building a relevance score model, from preprocessing and feature extraction to training, evaluation, and deployment. The approach is designed to be reproducible and scalable, allowing for efficient classification of news articles based on their relevance to specific topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('all_score_training.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>headlines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>‘Obviously I don’t think women are any less in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Layoffs hit crypto and real estate tech partic...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A brief recap of one of the worst weeks in cry...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Wells Fargo economist likens crypto collapse t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Crypto's Excruciating Week Has Traders Bracing...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1  \\\n",
       "0             0           0           0.0   \n",
       "1             1           1           1.0   \n",
       "2             2           2           2.0   \n",
       "3             3           3           3.0   \n",
       "4             4           4           4.0   \n",
       "\n",
       "                                           headlines  target  \n",
       "0  ‘Obviously I don’t think women are any less in...     1.0  \n",
       "1  Layoffs hit crypto and real estate tech partic...     1.0  \n",
       "2  A brief recap of one of the worst weeks in cry...     1.0  \n",
       "3  Wells Fargo economist likens crypto collapse t...     1.0  \n",
       "4  Crypto's Excruciating Week Has Traders Bracing...     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1187</td>\n",
       "      <td>0.684939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>546</td>\n",
       "      <td>0.315061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     counts         %\n",
       "0.0    1187  0.684939\n",
       "1.0     546  0.315061"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = training_df['target'].value_counts()\n",
    "p = training_df['target'].value_counts(normalize=True)\n",
    "pd.concat([c,p], axis=1, keys=['counts', '%'])\n",
    "# final_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "training_df.drop(['Unnamed: 0.1'],axis=1,inplace=True)\n",
    "training_df.drop(['Unnamed: 0.2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘Obviously I don’t think women are any less in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layoffs hit crypto and real estate tech partic...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A brief recap of one of the worst weeks in cry...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wells Fargo economist likens crypto collapse t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crypto's Excruciating Week Has Traders Bracing...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  target\n",
       "0  ‘Obviously I don’t think women are any less in...     1.0\n",
       "1  Layoffs hit crypto and real estate tech partic...     1.0\n",
       "2  A brief recap of one of the worst weeks in cry...     1.0\n",
       "3  Wells Fargo economist likens crypto collapse t...     1.0\n",
       "4  Crypto's Excruciating Week Has Traders Bracing...     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/arturoolivera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/arturoolivera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arturoolivera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary NLTK downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Custom transformer for text cleaning\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        cleaned_data = X.astype(str).map(lambda x: x.lower())\n",
    "        cleaned_data = cleaned_data.map(lambda x: re.sub('[^A-Za-z0-9]+', ' ', x))\n",
    "        return cleaned_data\n",
    "\n",
    "# Custom transformer for stop words removal\n",
    "class StopWordsRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        removed_stop_words = X.apply(lambda x: ' '.join([word for word in x.split() if word not in self.stop_words]))\n",
    "        return removed_stop_words\n",
    "\n",
    "# Custom transformer for lemmatization\n",
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        lemmatized_data = X.apply(lambda x: ' '.join([self.lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "        return lemmatized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('stop_words_remover', StopWordsRemover()),\n",
    "    ('lemmatizer', Lemmatizer()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.99      0.94       238\n",
      "         1.0       0.98      0.76      0.86       109\n",
      "\n",
      "    accuracy                           0.92       347\n",
      "   macro avg       0.94      0.88      0.90       347\n",
      "weighted avg       0.92      0.92      0.92       347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming `final_df` is your DataFrame and `headlines` is the column with text data\n",
    "X = training_df['headlines']\n",
    "y = training_df['target'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=training_df['target'], random_state=42)\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Scores:\n",
      "Accuracy: 0.974025974025974\n",
      "Precision: 0.9878345498783455\n",
      "Recall: 0.9290617848970252\n",
      "F1 Score: 0.9575471698113207\n",
      "ROC AUC Score: 0.961896540499092\n",
      "\n",
      "Test Set Scores:\n",
      "Accuracy: 0.9193083573487032\n",
      "Precision: 0.9764705882352941\n",
      "Recall: 0.7614678899082569\n",
      "F1 Score: 0.8556701030927835\n",
      "ROC AUC Score: 0.8765322642818596\n",
      "Confusion Matrix:\n",
      "[[236   2]\n",
      " [ 26  83]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "\n",
    "# Training set scores\n",
    "print(\"Training Set Scores:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_train, y_train_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_train, y_train_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_train, y_train_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_train, y_train_pred)}\")\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Test set scores\n",
    "print(\"\\nTest Set Scores:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storing the model for later use\n",
    "pickle.dump(pipeline, open('RelScoreModel_GA.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Case Study File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_study = pd.read_csv('GA_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_mobile</th>\n",
       "      <th>title</th>\n",
       "      <th>seendate</th>\n",
       "      <th>socialimage</th>\n",
       "      <th>domain</th>\n",
       "      <th>language</th>\n",
       "      <th>sourcecountry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.yahoo.com/ai-scams-missouri-warns...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Scams : Missouri warns voices of loved ones...</td>\n",
       "      <td>20240219T204500Z</td>\n",
       "      <td>https://media.zenfs.com/en/ktvi_articles_498/2...</td>\n",
       "      <td>news.yahoo.com</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.americanbanker.com/opinion/regulat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regulators should reexamine their assumptions ...</td>\n",
       "      <td>20240219T194500Z</td>\n",
       "      <td>https://source-media-brightspot.s3.us-east-1.a...</td>\n",
       "      <td>americanbanker.com</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://biztoc.com/x/97e1450bfef84362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korean Political Party Eyes Crypto Revol...</td>\n",
       "      <td>20240219T130000Z</td>\n",
       "      <td>https://c.biztoc.com/p/97e1450bfef84362/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://biztoc.com/x/5c2110519540e5cf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unraveling the Mystery Behind XRP Price Underp...</td>\n",
       "      <td>20240219T103000Z</td>\n",
       "      <td>https://c.biztoc.com/p/5c2110519540e5cf/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://biztoc.com/x/2f038851769a9841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cryptocurrency Rankings : Solana Claims the Co...</td>\n",
       "      <td>20240219T181500Z</td>\n",
       "      <td>https://c.biztoc.com/p/2f038851769a9841/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url url_mobile  \\\n",
       "0  https://news.yahoo.com/ai-scams-missouri-warns...        NaN   \n",
       "1  https://www.americanbanker.com/opinion/regulat...        NaN   \n",
       "2              https://biztoc.com/x/97e1450bfef84362        NaN   \n",
       "3              https://biztoc.com/x/5c2110519540e5cf        NaN   \n",
       "4              https://biztoc.com/x/2f038851769a9841        NaN   \n",
       "\n",
       "                                               title          seendate  \\\n",
       "0  AI Scams : Missouri warns voices of loved ones...  20240219T204500Z   \n",
       "1  Regulators should reexamine their assumptions ...  20240219T194500Z   \n",
       "2  South Korean Political Party Eyes Crypto Revol...  20240219T130000Z   \n",
       "3  Unraveling the Mystery Behind XRP Price Underp...  20240219T103000Z   \n",
       "4  Cryptocurrency Rankings : Solana Claims the Co...  20240219T181500Z   \n",
       "\n",
       "                                         socialimage              domain  \\\n",
       "0  https://media.zenfs.com/en/ktvi_articles_498/2...      news.yahoo.com   \n",
       "1  https://source-media-brightspot.s3.us-east-1.a...  americanbanker.com   \n",
       "2     https://c.biztoc.com/p/97e1450bfef84362/s.webp          biztoc.com   \n",
       "3     https://c.biztoc.com/p/5c2110519540e5cf/s.webp          biztoc.com   \n",
       "4     https://c.biztoc.com/p/2f038851769a9841/s.webp          biztoc.com   \n",
       "\n",
       "  language  sourcecountry  \n",
       "0  English  United States  \n",
       "1  English  United States  \n",
       "2  English            NaN  \n",
       "3  English            NaN  \n",
       "4  English            NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14004 entries, 0 to 14003\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   url            14004 non-null  object\n",
      " 1   url_mobile     2194 non-null   object\n",
      " 2   title          14002 non-null  object\n",
      " 3   seendate       14004 non-null  object\n",
      " 4   socialimage    7936 non-null   object\n",
      " 5   domain         14004 non-null  object\n",
      " 6   language       14004 non-null  object\n",
      " 7   sourcecountry  11462 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 875.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_study.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_proba = pipeline.predict_proba(df_study['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78981543, 0.21018457],\n",
       "       [0.4341361 , 0.5658639 ],\n",
       "       [0.30248348, 0.69751652],\n",
       "       ...,\n",
       "       [0.82172314, 0.17827686],\n",
       "       [0.88688625, 0.11311375],\n",
       "       [0.59431383, 0.40568617]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_study['relevance_probability']= study_proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strength_study = pipeline.predict(df_study['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_study['relevance_class']=strength_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_mobile</th>\n",
       "      <th>title</th>\n",
       "      <th>seendate</th>\n",
       "      <th>socialimage</th>\n",
       "      <th>domain</th>\n",
       "      <th>language</th>\n",
       "      <th>sourcecountry</th>\n",
       "      <th>relevance_probability</th>\n",
       "      <th>relevance_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://news.yahoo.com/ai-scams-missouri-warns...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI Scams : Missouri warns voices of loved ones...</td>\n",
       "      <td>20240219T204500Z</td>\n",
       "      <td>https://media.zenfs.com/en/ktvi_articles_498/2...</td>\n",
       "      <td>news.yahoo.com</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.210185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.americanbanker.com/opinion/regulat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regulators should reexamine their assumptions ...</td>\n",
       "      <td>20240219T194500Z</td>\n",
       "      <td>https://source-media-brightspot.s3.us-east-1.a...</td>\n",
       "      <td>americanbanker.com</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.565864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://biztoc.com/x/97e1450bfef84362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korean Political Party Eyes Crypto Revol...</td>\n",
       "      <td>20240219T130000Z</td>\n",
       "      <td>https://c.biztoc.com/p/97e1450bfef84362/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697517</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://biztoc.com/x/5c2110519540e5cf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unraveling the Mystery Behind XRP Price Underp...</td>\n",
       "      <td>20240219T103000Z</td>\n",
       "      <td>https://c.biztoc.com/p/5c2110519540e5cf/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369046</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://biztoc.com/x/2f038851769a9841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cryptocurrency Rankings : Solana Claims the Co...</td>\n",
       "      <td>20240219T181500Z</td>\n",
       "      <td>https://c.biztoc.com/p/2f038851769a9841/s.webp</td>\n",
       "      <td>biztoc.com</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url url_mobile  \\\n",
       "0  https://news.yahoo.com/ai-scams-missouri-warns...        NaN   \n",
       "1  https://www.americanbanker.com/opinion/regulat...        NaN   \n",
       "2              https://biztoc.com/x/97e1450bfef84362        NaN   \n",
       "3              https://biztoc.com/x/5c2110519540e5cf        NaN   \n",
       "4              https://biztoc.com/x/2f038851769a9841        NaN   \n",
       "\n",
       "                                               title          seendate  \\\n",
       "0  AI Scams : Missouri warns voices of loved ones...  20240219T204500Z   \n",
       "1  Regulators should reexamine their assumptions ...  20240219T194500Z   \n",
       "2  South Korean Political Party Eyes Crypto Revol...  20240219T130000Z   \n",
       "3  Unraveling the Mystery Behind XRP Price Underp...  20240219T103000Z   \n",
       "4  Cryptocurrency Rankings : Solana Claims the Co...  20240219T181500Z   \n",
       "\n",
       "                                         socialimage              domain  \\\n",
       "0  https://media.zenfs.com/en/ktvi_articles_498/2...      news.yahoo.com   \n",
       "1  https://source-media-brightspot.s3.us-east-1.a...  americanbanker.com   \n",
       "2     https://c.biztoc.com/p/97e1450bfef84362/s.webp          biztoc.com   \n",
       "3     https://c.biztoc.com/p/5c2110519540e5cf/s.webp          biztoc.com   \n",
       "4     https://c.biztoc.com/p/2f038851769a9841/s.webp          biztoc.com   \n",
       "\n",
       "  language  sourcecountry  relevance_probability  relevance_class  \n",
       "0  English  United States               0.210185              0.0  \n",
       "1  English  United States               0.565864              1.0  \n",
       "2  English            NaN               0.697517              1.0  \n",
       "3  English            NaN               0.369046              0.0  \n",
       "4  English            NaN               0.512854              1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study.to_csv('GA_data_wrelevance.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
